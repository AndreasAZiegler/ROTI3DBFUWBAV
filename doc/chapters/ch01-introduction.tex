% !TEX root = ../thesis.tex

% set counter to n-1:
\setcounter{chapter}{0}

\chapter{Introduction}

Object tracking is an important building block for many interactive systems, especially for robotic systems interacting with humans. State-of-the-art robust approaches detect and recognize a small number of pre-defined	object types like humans, birds	or cars which were learned beforehand during the training of the detector. As for many applications tracking of arbitrary objects is desirable, i.e. a bottle, a hand, an animal, a face etc., these object trackers are not enough flexible. Online visual tracking on the other hand deals with the challenging task of tracking an object based on an initial bounding box in an image. This faces the fundamental problem of very limited labeled data and as a consequence any such tracking approach has to balance plasticity and drift, in particular when an object should be re-detected after loss of tracking. In this semester project a new approach is proposed. A fusion of \acf{UWB} and visual measurements to track an object in 3D by fusing both modalities in a principled manner.

This semester project focuses on visual tracking with correlation filters. This is typically susceptible to drift and has low accuracy in the radial direction. The aim is to compensate for this with an additional existing sensor modality based on multilateration with \ac{UWB} signals. A single tracker consists of multiple \ac{UWB} units that track a single \ac{UWB} unit on the target, providing a 3D position and covariance of the target. Because of the arrangement of the \ac{UWB} units the tangential accuracy of the \ac{UWB} position is relatively low. The visual tracker will provide a 2D measurement. Together both observations should be fused in a principled manner using an \acf{EKF} that will combine the strength of both approaches.